{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_test = [\"youpi\",\"le\",\"chien\",\"est\",\"heureux\",\"devant\",\"le\",\"camaieu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_HAL_matrix(document):\n",
    "    words = []\n",
    "    for word in document:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "    n = len(words)\n",
    "    hal_dict_matrix = {}\n",
    "    for word in words:\n",
    "        hal_dict_matrix[word]={}\n",
    "        for word2 in words:\n",
    "            hal_dict_matrix[word][word2] = 0\n",
    "        \n",
    "    return hal_dict_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "hal_dict_matrix_test= create_HAL_matrix(document_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(hal_dict_matrix_test.values())[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_HAL_matrix(document,hal_dict_matrix,window_size):\n",
    "    window_size_updated = window_size\n",
    "    len_doc = len(document)\n",
    "    for i in range(len_doc):\n",
    "        word = document[i]\n",
    "        if i+window_size >=len_doc:\n",
    "            window_size_updated += -1\n",
    "        for k in range(1,window_size_updated+1):\n",
    "            word2 = document[i+k]\n",
    "            hal_dict_matrix[word][word2] += window_size-k+1\n",
    "    return hal_dict_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'youpi': {'youpi': 0,\n",
       "  'le': 5,\n",
       "  'chien': 4,\n",
       "  'est': 3,\n",
       "  'heureux': 2,\n",
       "  'devant': 1,\n",
       "  'camaieu': 0},\n",
       " 'le': {'youpi': 0,\n",
       "  'le': 1,\n",
       "  'chien': 5,\n",
       "  'est': 4,\n",
       "  'heureux': 3,\n",
       "  'devant': 2,\n",
       "  'camaieu': 5},\n",
       " 'chien': {'youpi': 0,\n",
       "  'le': 2,\n",
       "  'chien': 0,\n",
       "  'est': 5,\n",
       "  'heureux': 4,\n",
       "  'devant': 3,\n",
       "  'camaieu': 1},\n",
       " 'est': {'youpi': 0,\n",
       "  'le': 3,\n",
       "  'chien': 0,\n",
       "  'est': 0,\n",
       "  'heureux': 5,\n",
       "  'devant': 4,\n",
       "  'camaieu': 2},\n",
       " 'heureux': {'youpi': 0,\n",
       "  'le': 4,\n",
       "  'chien': 0,\n",
       "  'est': 0,\n",
       "  'heureux': 0,\n",
       "  'devant': 5,\n",
       "  'camaieu': 3},\n",
       " 'devant': {'youpi': 0,\n",
       "  'le': 5,\n",
       "  'chien': 0,\n",
       "  'est': 0,\n",
       "  'heureux': 0,\n",
       "  'devant': 0,\n",
       "  'camaieu': 4},\n",
       " 'camaieu': {'youpi': 0,\n",
       "  'le': 0,\n",
       "  'chien': 0,\n",
       "  'est': 0,\n",
       "  'heureux': 0,\n",
       "  'devant': 0,\n",
       "  'camaieu': 0}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_HAL_matrix(document_test,hal_dict_matrix_test,window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hal_dict_to_matrix(hal_dict_matrix):\n",
    "    hal_matrix = []\n",
    "    for i in range(len(hal_dict_matrix.keys())):\n",
    "        hal_matrix.append(list(list(hal_dict_matrix_test.values())[i].values()))\n",
    "    return hal_matrix,list(hal_dict_matrix.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 5, 4, 3, 2, 1, 0],\n",
       " [0, 1, 5, 4, 3, 2, 5],\n",
       " [0, 2, 0, 5, 4, 3, 1],\n",
       " [0, 3, 0, 0, 5, 4, 2],\n",
       " [0, 4, 0, 0, 0, 5, 3],\n",
       " [0, 5, 0, 0, 0, 0, 4],\n",
       " [0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hal_matrix_test,words_list_test = hal_dict_to_matrix(hal_dict_matrix_test)\n",
    "hal_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hal_to_symmetric(hal_matrix):\n",
    "    return hal_matrix + np.transpose(hal_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 5, 4, 3, 2, 1, 0],\n",
       "       [5, 2, 7, 7, 7, 7, 5],\n",
       "       [4, 7, 0, 5, 4, 3, 1],\n",
       "       [3, 7, 5, 0, 5, 4, 2],\n",
       "       [2, 7, 4, 5, 0, 5, 3],\n",
       "       [1, 7, 3, 4, 5, 0, 4],\n",
       "       [0, 5, 1, 2, 3, 4, 0]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hal_matrix_symmetric_test = hal_to_symmetric(hal_matrix_test)\n",
    "hal_matrix_symmetric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['youpi', 'le', 'chien', 'est', 'heureux', 'devant', 'camaieu']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(hal_matrix_symmetric):\n",
    "    n_words = len(hal_matrix_symmetric)\n",
    "    doc_vector = np.array([0]*n_words)\n",
    "    for i in range(n_words):\n",
    "        doc_vector[i] = sum(hal_matrix_symmetric[i])\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 40, 24, 26, 26, 24, 15])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector_test = document_vector(hal_matrix_symmetric_test)\n",
    "document_vector_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_vector(hal_matrix_symmetric,words_list,word_to_extract):\n",
    "    word_position = words_list.index(word_to_extract)\n",
    "    return hal_matrix_symmetric[word_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 7, 4, 5, 0, 5, 3])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector_test = extract_word_vector(hal_matrix_symmetric_test,words_list_test,\"heureux\")\n",
    "word_vector_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 0, 5, 4, 3, 1])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector_test2 = extract_word_vector(hal_matrix_symmetric_test,words_list_test,\"chien\")\n",
    "word_vector_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(word_vector):\n",
    "    return word_vector/(np.linalg.vector_norm(word_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1767767 , 0.61871843, 0.35355339, 0.44194174, 0.        ,\n",
       "       0.44194174, 0.26516504])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_vector(word_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_from_word_vectors(word_vector_normalised,word_vector_normalised2):\n",
    "    word_vector_ort = word_vector_normalised2 - np.dot(word_vector_normalised2,word_vector_normalised)*word_vector_normalised\n",
    "    word_vector_normalised_ort = normalize_vector(word_vector_ort)\n",
    "    return word_vector_normalised,word_vector_normalised_ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1767767 , 0.61871843, 0.35355339, 0.44194174, 0.        ,\n",
       "        0.44194174, 0.26516504]),\n",
       " array([ 0.39606668,  0.24881112, -0.50777779,  0.17772223,  0.64995557,\n",
       "        -0.14725556, -0.21834445]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector_test_normed = normalize_vector(word_vector_test)\n",
    "word_vector_test_normed2 = normalize_vector(word_vector_test2)\n",
    "base_vector1_test,base_vector2_test = base_from_word_vectors(word_vector_test_normed,word_vector_test_normed2)\n",
    "base_from_word_vectors(word_vector_test_normed,word_vector_test_normed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.2575874026256565e-16)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(base_vector1_test,base_vector2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_doc_onto_base(base_vector1,base_vector2,document_vector):\n",
    "    \n",
    "    alpha = np.dot(base_vector1,document_vector)\n",
    "    alpha_ort = np.dot(base_vector2,document_vector)\n",
    "    normalisation_factor = np.sqrt(alpha**2+alpha_ort**2)\n",
    "    return alpha/normalisation_factor,alpha_ort/normalisation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9585511833141687), np.float64(0.28492039057780144))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_test,alpha_ort_test = project_doc_onto_base(base_vector1_test,base_vector2_test,document_vector_test)\n",
    "alpha_test,alpha_ort_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9999999999999999), np.float64(67.48333127521195))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(alpha_test**2+alpha_ort_test**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_matrices(base_vector1,word_vector_normed2):\n",
    "    p = np.dot(base_vector1,word_vector_normed2)\n",
    "    B_mat = np.array([[2*p**2-1 ,2*p*np.sqrt(1-p**2)],[2*p*np.sqrt(1-p**2),1-2*p**2]])\n",
    "    B_mat_x = np.array([[-2*p*np.sqrt(1-p**2),2*p**2-1],[2*p**2-1,2*p*np.sqrt(1-p**2)]])\n",
    "    B_mat_plus = -(B_mat+B_mat_x)/np.sqrt(2)\n",
    "    B_mat_minus = (B_mat-B_mat_x)/np.sqrt(2)\n",
    "    return B_mat_plus,B_mat_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.41782144, -0.90852916],\n",
       "        [-0.90852916, -0.41782144]]),\n",
       " array([[ 0.90852916,  0.41782144],\n",
       "        [ 0.41782144, -0.90852916]]))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_mat_plus_test,B_mat_minus_test = B_matrices(base_vector1_test,word_vector_test_normed2)\n",
    "B_mat_plus_test,B_mat_minus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mat = [[1,0],[0,-1]]\n",
    "A_mat_x = [[0,1],[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esp(alpha,alpha_ort,matrix):\n",
    "    document_vector = np.array([alpha,alpha_ort])\n",
    "    return np.dot( document_vector,np.matmul(matrix,document_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.837640742065986), np.float64(0.8376407420659859))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esp(alpha_test,alpha_ort_test,A_mat),2*alpha_test**2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_query(A_mat,A_mat_x,B_mat_plus,B_mat_minus,alpha,alpha_ort):\n",
    "    esp_A_Bplus = esp(alpha,alpha_ort,np.matmul(A_mat,B_mat_plus))\n",
    "    esp_Ax_Bplus = esp(alpha,alpha_ort,np.matmul(A_mat_x,B_mat_plus))\n",
    "    esp_A_Bminus = esp(alpha,alpha_ort,np.matmul(A_mat,B_mat_minus))\n",
    "    esp_Ax_Bminus = esp(alpha,alpha_ort,np.matmul(A_mat_x,B_mat_minus))\n",
    "    return np.abs(esp_A_Bplus + esp_Ax_Bplus) + np.abs(esp_A_Bminus - esp_Ax_Bminus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.490707723151009)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_query(A_mat,A_mat_x,B_mat_plus_test,B_mat_minus_test,alpha_test,alpha_ort_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
